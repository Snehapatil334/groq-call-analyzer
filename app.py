# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xcsOBEQP3fa9XZ3jen2yVO6QqiJ-LUGU
"""

import os
import json
from fastapi import FastAPI
from pydantic import BaseModel
from groq import Groq
from dotenv import load_dotenv
import pandas as pd

# Load environment variables from .env file
load_dotenv()

# Initialize the FastAPI app
app = FastAPI(
    title="Call Transcript Analyzer",
    description="An API to summarize and analyze the sentiment of call transcripts using Groq."
)

# Initialize the Groq client
# This will use the GROQ_API_KEY from your .env file
try:
    client = Groq(api_key=os.getenv("GROQ_API_KEY"))
except Exception as e:
    print(f"Error initializing Groq client: {e}")
    # You might want to handle this more gracefully
    client = None

# Define the data model for the request body
class TranscriptInput(BaseModel):
    text: str

# Define the data model for the response
class AnalysisOutput(BaseModel):
    original_transcript: str
    summary: str
    sentiment: str

# Define the CSV file path
CSV_FILE = "call_analysis.csv"

@app.post("/analyze", response_model=AnalysisOutput)
async def analyze_transcript(data: TranscriptInput):
    """
    Accepts a transcript, analyzes it using Groq for summary and sentiment,
    and saves the result to a CSV file.
    """
    transcript = data.text

    # System prompt to instruct the AI
    system_prompt = (
        "You are an expert AI assistant for analyzing customer call transcripts. "
        "Your task is to provide a concise summary and determine the customer's overall sentiment. "
        "Please return the output in a clean JSON format with two keys: 'summary' and 'sentiment'. "
        "The summary should be 2-3 sentences long. "
        "The sentiment must be one of the following: 'Positive', 'Neutral', or 'Negative'."
    )

    # Make the API call to Groq
    chat_completion = client.chat.completions.create(
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": transcript},
        ],
        model="moonshotai/kimi-k2-instruct-0905",
        temperature=0.2,  # Lower temperature for more deterministic results
        response_format={"type": "json_object"},
    )

    # Extract and parse the JSON response
    response_content = chat_completion.choices[0].message.content
    analysis_result = json.loads(response_content)

    summary = analysis_result.get("summary", "Summary not available.")
    sentiment = analysis_result.get("sentiment", "Sentiment not available.")

    # Print the results to the console
    print("--- Analysis Complete ---")
    print(f"Original Transcript:\n{transcript}\n")
    print(f"Summary: {summary}\n")
    print(f"Sentiment: {sentiment}\n")
    print("-------------------------")

    # Save the output to a .csv file
    output_data = {
        "Transcript": [transcript],
        "Summary": [summary],
        "Sentiment": [sentiment]
    }
    df = pd.DataFrame(output_data)

    # Check if file exists to decide whether to write headers
    file_exists = os.path.isfile(CSV_FILE)
    df.to_csv(CSV_FILE, mode='a', header=not file_exists, index=False)

    return {
        "original_transcript": transcript,
        "summary": summary,
        "sentiment": sentiment
    }

@app.get("/")
def read_root():
    return {"message": "Welcome to the Call Transcript Analyzer API. Go to /docs to test the endpoint."}